2025-08-12 22:25:18,552 - __main__ - INFO - Starting LLM Stress Test
2025-08-12 22:25:18,552 - __main__ - INFO - Configuration loaded: {'questions': 10, 'concurrent': 2, 'url': 'http://localhost:11434', 'server_name': 'MacBook Pro M1', 'model': 'gemma3:12b', 'timeout': 120.0, 'max_keepalive_connections': 20}
2025-08-12 22:25:18,552 - __main__ - INFO - Generated filename: result_MacBook-Pro-M1_gemma3_12b
2025-08-12 22:25:18,552 - __main__ - INFO - Loaded 10 questions
2025-08-12 22:25:18,585 - __main__ - INFO - Testing connection to http://localhost:11434/v1
2025-08-12 22:25:18,697 - httpx - INFO - HTTP Request: GET http://localhost:11434/v1/models "HTTP/1.1 200 OK"
2025-08-12 22:25:18,698 - __main__ - INFO - Connection successful. Available models: ['gemma3n:e4b', 'Qwen2.5:14b-instruct', 'llama3-groq-tool-use:8b', 'gemma3:12b', 'deepseek-r1:14b', 'mistral:latest', 'bge-m3:latest', 'mxbai-embed-large:latest', 'bge-large:latest', 'gemma2:latest', 'jina/jina-embeddings-v2-base-de:latest', 'jeffh/intfloat-multilingual-e5-large:f16', 'nomic-embed-text:latest', 'paraphrase-multilingual:latest']
2025-08-12 22:25:18,698 - __main__ - INFO - Starting warmup phase to measure LLM loading time...
2025-08-12 22:25:26,452 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:25:26,460 - __main__ - INFO - [WARMUP] Model loading completed in 7761.9ms
2025-08-12 22:25:26,460 - __main__ - INFO - Running first question again without loading time...
2025-08-12 22:25:26,871 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:25:26,876 - __main__ - INFO - Question processed in 414.7ms, 8 tokens, quality: 0.461
2025-08-12 22:25:26,876 - __main__ - INFO - LLM load time calculated: 7347.2ms (warmup: 7761.9ms, real: 414.7ms)
2025-08-12 22:25:26,876 - __main__ - INFO - Processing remaining questions with concurrency: 2
2025-08-12 22:26:05,730 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:26:05,734 - __main__ - INFO - Question processed in 38856.5ms, 500 tokens, quality: 0.589
2025-08-12 22:26:05,822 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:26:05,826 - __main__ - INFO - Question processed in 38947.2ms, 500 tokens, quality: 0.567
2025-08-12 22:26:44,792 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:26:44,798 - __main__ - INFO - Question processed in 38970.3ms, 500 tokens, quality: 0.536
2025-08-12 22:26:44,799 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:26:44,800 - __main__ - INFO - Question processed in 38973.4ms, 500 tokens, quality: 0.521
2025-08-12 22:27:24,601 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:27:24,602 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
2025-08-12 22:27:24,603 - __main__ - INFO - Question processed in 39801.3ms, 500 tokens, quality: 0.594
2025-08-12 22:27:24,605 - __main__ - INFO - Question processed in 39803.5ms, 500 tokens, quality: 0.54
