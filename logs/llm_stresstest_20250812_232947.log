2025-08-12 23:29:47,236 - __main__ - INFO - Starting LLM Stress Test
2025-08-12 23:29:47,244 - __main__ - INFO - Configuration loaded: {'questions': 10, 'concurrent': 2, 'url': 'http://localhost:11434', 'server_name': 'PC-FIN', 'model': 'gemma3:12b', 'timeout': 120.0, 'max_keepalive_connections': 20}
2025-08-12 23:29:47,244 - __main__ - INFO - Generated filename: result_PC-FIN_gemma3_12b
2025-08-12 23:29:47,245 - __main__ - INFO - Loaded 10 questions
2025-08-12 23:29:47,422 - __main__ - INFO - Testing connection to http://localhost:11434/v1
2025-08-12 23:29:47,596 - httpx - INFO - HTTP Request: GET http://localhost:11434/v1/models "HTTP/1.1 200 OK"
2025-08-12 23:29:47,596 - __main__ - INFO - Connection successful. Available models: ['deepseek-r1:14b', 'mistral-small:latest', 'mxbai-embed-large:latest', 'nomic-embed-text:latest', 'jina/jina-embeddings-v2-base-de:latest', 'jeffh/intfloat-multilingual-e5-large:f16', 'yxchia/paraphrase-multilingual-minilm-l12-v2:Q4_K_M', 'llama3.2:latest']
2025-08-12 23:29:47,666 - __main__ - INFO - Starting warmup phase to measure LLM loading time...
2025-08-12 23:29:47,671 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,671 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,671 - __main__ - INFO - Running first question again without loading time...
2025-08-12 23:29:47,722 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,722 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,722 - __main__ - INFO - LLM load time calculated: 0.0ms (warmup: 0.0ms, real: 0.0ms)
2025-08-12 23:29:47,722 - __main__ - INFO - Processing remaining questions with concurrency: 2
2025-08-12 23:29:47,722 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,728 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,771 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,771 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,823 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,824 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,824 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,825 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,865 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,865 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,873 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,873 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,922 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,923 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,923 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,924 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,972 - httpx - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 404 Not Found"
2025-08-12 23:29:47,972 - __main__ - ERROR - Error processing question: Error code: 404 - {'error': {'message': 'model "gemma3:12b" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}
2025-08-12 23:29:47,972 - __main__ - INFO - Results saved to results\result_PC-FIN_gemma3_12b.json
2025-08-12 23:29:47,972 - __main__ - INFO - Test completed successfully. Results saved to results/result_PC-FIN_gemma3_12b.json
2025-08-12 23:29:47,972 - __main__ - INFO - Test completed successfully
